{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readout Limits: 1.2\n",
    "## Assessing a readout - PvA or AvP\n",
    "\n",
    "The standard approach to assess a complex model's ability to 'predict' a value is to characterize the 'predicted-vs-actual' plot.\n",
    "Importantly, unlike the scientific standard of 'y-vs-x', in ML this plot typically has predicted on the 'x-axis' and actual on the 'y-axis'.\n",
    "In the ML world there are strong arguments to ensure the predicted stays on the x-axis, but in the DBS readout world our goals are different.\n",
    "\n",
    "In this notebook I'll address the standard PvA plot and compare it to a proposed 'readout plot' for the assessment of a neural readout of disease.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import scipy.signal as signal\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(110)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "matplotlib.rcParams['figure.figsize'] = [20, 15]\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from ipywidgets import interact, interactive, fixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class coverage:\n",
    "    def __init__(self):\n",
    "        self.Nt = 1000\n",
    "        self.N = 200\n",
    "        self.behav_dim = 30\n",
    "        self.brain_dim = 50\n",
    "        self.measure_dim = 2\n",
    "\n",
    "        self.gamma_ratio = 1/50\n",
    "    \n",
    "    def design_gamma(self):\n",
    "        self.gamma_b = np.random.choice([0,1],size=(self.behav_dim,self.brain_dim),p=[1-self.gamma_ratio,self.gamma_ratio])\n",
    "        \n",
    "    def run_sim(self):\n",
    "        gamma_b = self.gamma_b\n",
    "        \n",
    "        #Here we want to determine h_b parametrized by a coverage parameter [0,1]\n",
    "        disease_regions = np.sum(gamma_b,axis=1) #behav x 1\n",
    "        brain_importance = np.sum(gamma_b,axis=0) # bran x 1\n",
    "\n",
    "        #find all non-zero brain regions\n",
    "        b_i_idx = np.where(brain_importance > 0)[0]\n",
    "        #now take only coverage * b_i_idx regions randomly and that's your h\n",
    "        measurables = np.random.choice(b_i_idx,replace=False,size=(np.ceil(len(b_i_idx) * coverage).astype(np.int),))\n",
    "        #print(brain_importance)\n",
    "        #print(measurables)\n",
    "\n",
    "        h_b = np.zeros(shape=(len(measurables),brain_dim))\n",
    "        for ii,br in enumerate(measurables):\n",
    "            h_b[ii][br] = 1\n",
    "\n",
    "        injection = 0\n",
    "        #now do injection (including non-disease related brain regions into measurements)\n",
    "        b_n_idx = np.where(brain_importance == 0)[0] #brain, NOT important\n",
    "        #print(b_n_idx)\n",
    "        noise_sources = np.random.choice(b_n_idx,replace=False,size=(np.ceil(len(b_n_idx) * injection).astype(np.int),))\n",
    "        for ii,br in enumerate(noise_sources):\n",
    "            h_b[ii][br] = 1\n",
    "\n",
    "        #h_b = gamma_b\n",
    "        #h_b = np.random.choice([0,1],size=(measure_dim,brain_dim),p=[2/3,1/3])\n",
    "\n",
    "\n",
    "        x = np.random.normal(0,1,size=(brain_dim,N))\n",
    "\n",
    "        beta = np.dot(gamma_b,x)\n",
    "        c = np.sum(beta,axis=0)\n",
    "        y = (np.dot(h_b,x))\n",
    "        y += np.random.normal(0,noise_level,size=y.shape)\n",
    "\n",
    "        self.readout_model = LinearRegression().fit(y.T,c)\n",
    "        \n",
    "\n",
    "        self.x_test = np.random.normal(0,1,size=(brain_dim,Nt))\n",
    "        self.beta_test = np.dot(gamma_b,x_test)\n",
    "        self.c_test = np.sum(beta_test,axis=0)\n",
    "        self.y_test = np.dot(h_b,x_test)\n",
    "\n",
    "        self.pred_c = readout_model.predict(y_test.T)\n",
    "\n",
    "        \n",
    "    def comparison_plot(self):\n",
    "        pred_c = self.pred_c\n",
    "    \n",
    "        plt.subplot(221)\n",
    "        plt.scatter(pred_c,c_test)\n",
    "        plt.xlabel('Predicted');plt.ylabel('Actual')\n",
    "        assess_lr = LinearRegression(fit_intercept=True).fit(pred_c.reshape(-1,1),c_test.reshape(-1,1))\n",
    "        r2_fit_pva = r2_score(c_test,pred_c) #have to be careful here because the function takes (actual, then predicted) in arguments\n",
    "        plt.title('Slope'+str(assess_lr.coef_))\n",
    "        plt.plot([-10,10],[-10,10],linestyle='dotted')\n",
    "\n",
    "        plt.subplot(222)\n",
    "        plt.scatter(c_test,pred_c)\n",
    "        plt.xlabel('Actual');plt.ylabel('Predicted')\n",
    "        assess_rl = LinearRegression(fit_intercept=True).fit(c_test.reshape(-1,1),pred_c.reshape(-1,1))\n",
    "        r2_fit_avp = r2_score(pred_c,c_test)\n",
    "        plt.title('Slope'+str(assess_rl.coef_))\n",
    "        plt.plot([-10,10],[-10,10],linestyle='dotted')\n",
    "\n",
    "        plt.subplot(2,1,2)\n",
    "        plt.imshow(h_b)\n",
    "\n",
    "        plt.suptitle('R2:' + str((r2_fit_pva,'vs',r2_fit_avp)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framework\n",
    "The standard plot to assess a prediction model is the 'prediction-vs-actual' plot [cite]().\n",
    "Importantly, this plot is typically plotted with **prediction on the x-axis** and actual on the y-axis.\n",
    "There are arguments supporting this view when the focus is on inferring the actual from a predcited value [cite]().\n",
    "\n",
    "However, the alternative view provides a different, complementary view: **prediction on the y-axis** and actual on the x-axis.\n",
    "In this view, the model we use to assess our readout is:\n",
    "\n",
    "$$ \\hat{y} = m\\cdot  y + \\epsilon$$ where $\\epsilon$ is an error\n",
    "\n",
    "*Most of this becomes irrelevant with approaches that use 'total least squares' and don't put all the error in one variable or the other. These approaches would probably be preferred for more sophisticated work, but for the sake of our first-order readout assessment we'll assume the error is entirely in the prediction and not in the 'actual'*\n",
    "\n",
    "## Example System\n",
    "We'll work with a simple example system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def try_coverage(coverage=1.0,injection=0.0, noise_level=0.0):\n",
    "    behav_dim = 30\n",
    "    brain_dim = 50\n",
    "    measure_dim = 2\n",
    "\n",
    "    gamma_ratio = 1/50\n",
    "    gamma_b = np.random.choice([0,1],size=(behav_dim,brain_dim),p=[1-gamma_ratio,gamma_ratio])\n",
    "    #Here we want to determine h_b parametrized by a coverage parameter [0,1]\n",
    "    disease_regions = np.sum(gamma_b,axis=1) #behav x 1\n",
    "    brain_importance = np.sum(gamma_b,axis=0) # bran x 1\n",
    "    \n",
    "    #find all non-zero brain regions\n",
    "    b_i_idx = np.where(brain_importance > 0)[0]\n",
    "    #now take only coverage * b_i_idx regions randomly and that's your h\n",
    "    measurables = np.random.choice(b_i_idx,replace=False,size=(np.ceil(len(b_i_idx) * coverage).astype(np.int),))\n",
    "    #print(brain_importance)\n",
    "    #print(measurables)\n",
    "\n",
    "    h_b = np.zeros(shape=(behav_dim,brain_dim))\n",
    "    for ii,br in enumerate(measurables):\n",
    "        h_b[ii][br] = 1\n",
    "\n",
    "    injection = 0\n",
    "    #now do injection (including non-disease related brain regions into measurements)\n",
    "    b_n_idx = np.where(brain_importance == 0)[0] #brain, NOT important\n",
    "    #print(b_n_idx)\n",
    "    noise_sources = np.random.choice(b_n_idx,replace=False,size=(np.ceil(len(b_n_idx) * injection).astype(np.int),))\n",
    "    for ii,br in enumerate(noise_sources):\n",
    "        h_b[ii][br] = 1\n",
    "    \n",
    "    #h_b = gamma_b\n",
    "    #h_b = np.random.choice([0,1],size=(measure_dim,brain_dim),p=[2/3,1/3])\n",
    "\n",
    "    N = 200\n",
    "    x = np.random.normal(0,1,size=(brain_dim,N))\n",
    "\n",
    "    beta = np.dot(gamma_b,x)\n",
    "    c = np.sum(beta,axis=0)\n",
    "    y = (np.dot(h_b,x))\n",
    "    y += np.random.normal(0,noise_level,size=y.shape)\n",
    "\n",
    "    readout_model = LinearRegression().fit(y.T,c)\n",
    "\n",
    "    Nt = 1000\n",
    "    x_test = np.random.normal(0,1,size=(brain_dim,Nt))\n",
    "    beta_test = np.dot(gamma_b,x_test)\n",
    "    c_test = np.sum(beta_test,axis=0)\n",
    "    y_test = np.dot(h_b,x_test)\n",
    "\n",
    "    pred_c = readout_model.predict(y_test.T)\n",
    "\n",
    "    plt.subplot(221)\n",
    "    plt.scatter(pred_c,c_test)\n",
    "    plt.xlabel('Predicted');plt.ylabel('Actual')\n",
    "    assess_lr = LinearRegression(fit_intercept=True).fit(pred_c.reshape(-1,1),c_test.reshape(-1,1))\n",
    "    r2_fit_pva = r2_score(c_test,pred_c) #have to be careful here because the function takes (actual, then predicted) in arguments\n",
    "    plt.title('Slope'+str(assess_lr.coef_[0][0]) + ' R^2:' + str(r2_fit_pva))\n",
    "    plt.plot([-10,10],[-10,10],linestyle='dotted')\n",
    "\n",
    "    plt.subplot(222)\n",
    "    plt.scatter(c_test,pred_c)\n",
    "    plt.xlabel('Actual');plt.ylabel('Predicted')\n",
    "    assess_rl = LinearRegression(fit_intercept=True).fit(c_test.reshape(-1,1),pred_c.reshape(-1,1))\n",
    "    r2_fit_avp = r2_score(pred_c,c_test)\n",
    "    plt.title('Slope'+str(assess_rl.coef_[0][0]) + ' R^2:' + str(r2_fit_avp))\n",
    "    plt.plot([-10,10],[-10,10],linestyle='dotted')\n",
    "    \n",
    "    plt.subplot(2,1,2)\n",
    "    plt.imshow(h_b)\n",
    "    \n",
    "    #is there at least one H in a non-zero B?\n",
    "    at_least_one = np.sum(np.dot(np.abs(h_b>0),np.abs(gamma_b>0).T))\n",
    "    plt.suptitle('R2:' + str((r2_fit_pva,'vs',r2_fit_avp)) + ' ' + str(at_least_one))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e0722da56e40f6a95b58693fdf62f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='coverage', max=1.0, step=0.01), FloatSlider(value=0.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "readout_widg = interactive(try_coverage,coverage=(0.0,1.0,0.01),noise_level=(0.0,10.0,0.1))\n",
    "display(readout_widg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example **coverage** refers to what percentage of the number of brain regions known to be involved in behavior are actually being recorded from.\n",
    "\n",
    "**Injection** refers to how many brain regions known to *not* be involved in the disease mapping are being recorded from.\n",
    "\n",
    "Noise is the additive noise component in the final measurement of $\\vec{y}$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
