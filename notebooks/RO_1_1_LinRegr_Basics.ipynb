{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readout Limits: 1.1\n",
    "## A Primer on Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Linear regression will be a tool we use to assess our readout.\n",
    "Let's first talk a bit about what the pieces of a linear regression mean: slope, intercept, $r^2$, mean-square error, etc.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal as sig\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "from IPython.display import clear_output, display, HTML\n",
    "np.random.seed(42)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "matplotlib.rcParams['figure.figsize'] = [20, 15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25bda73b6c2d484fa9a9fee5144ad3c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='m0', max=1.0, min=-1.0), FloatSlider(value=0.0, desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.random.uniform(-10,10,1000)\n",
    "\n",
    "\n",
    "def noise_exercise(x,m0=0.0,m1=0.0,m2=1.0,m3=0,n1=0,n2=2,samps=1000):\n",
    "    m = np.array([m0,m1,m2,m3]).T\n",
    "    x = x[:samps]\n",
    "    y = np.dot(m,np.array([x**3,x**2,x,1])) + np.random.normal(n1,n2,size=x.shape)\n",
    "    x_real = np.linspace(-10,10,10)\n",
    "    y_real = np.dot(m,np.array([x_real**3,x_real**2,x_real,1]))\n",
    "\n",
    "    x = x.reshape(-1,1)\n",
    "    y = y.reshape(-1,1)\n",
    "\n",
    "    plt.scatter(x,y)\n",
    "    plt.plot(x_real,y_real,color='red')\n",
    "    plt.xlim((-10,10))\n",
    "    plt.ylim((-20,20))\n",
    "\n",
    "    # calculate our stats for the regression\n",
    "    r_model = LinearRegression()\n",
    "    r_model.fit(x,y)\n",
    "    y_pred = r_model.predict(x)\n",
    "\n",
    "    pred_line = r_model.coef_ * x_real + r_model.intercept_\n",
    "    plt.plot(x_real,pred_line.T,color='green')\n",
    "    \n",
    "    rmse = mean_squared_error(y_pred,y)\n",
    "    r2 = r2_score(y,y_pred)\n",
    "\n",
    "    plt.text(11,10,'R2 ' + str(r2))\n",
    "    plt.text(11,5,'Slope ' + str(r_model.coef_))\n",
    "    plt.text(11,0,'Intercept ' + str(r_model.intercept_))\n",
    "\n",
    "noise_widg = interactive(noise_exercise,x=fixed(x),m0=(-1.0,1.0,0.1),m1=(-1.0,1.0,0.1),m2=(-1.0,1.0,0.1),m3=(0.0,10.0,0.1),n1=(0.0,5.0,0.1),n2=(0.0,20.0,1.0),samps=(2,100,1))\n",
    "display(noise_widg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try this:\n",
    "    Set the m0 to 0.0\n",
    "    Set the m1 to 0.3 -> This makes the true relationship an $x^2$ relationship.\n",
    "    Set m2 at 1.0\n",
    "    Set the noise n2 at something high first, then something low\n",
    "    Finally, set the samples to something around 50\n",
    "    \n",
    "Tweak around with it but what you'll see is that you linear regression line has a poor $r^2$ fit score.\n",
    "\n",
    "This is expected because, well, you're trying to fit an $x^2$ relationship with an $x^1$ model. This is a fundamental model mismatch.\n",
    "\n",
    "Now try setting the M0 to 1.0\n",
    "You'll see the $r^2$ improve.\n",
    "This is because an $x^3$ is better fit by a linear model since it doesn't \"turn around\" in negative numbers.\n",
    "\n",
    "If we moved this up to $x^4$ the $r^2$ would get bad again. Try it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted vs Actual\n",
    "Now that we're familiar with the basics of linear regression, let's get to the focus: we're trying to predict something.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774521365e364fb0afaff22b5a7551de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='noise1', max=10), IntSlider(value=0, description='h1', m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pva(noise1=1,h1=0,h4=0):\n",
    "    t = np.linspace(0,10,1000)\n",
    "    x = []\n",
    "    for ii in range(5):\n",
    "        x.append(np.sin(2 * np.pi * np.random.uniform(0,10) * t) + np.random.normal(0,noise1,size=t.shape))\n",
    "\n",
    "    x = np.array(x)\n",
    "    gamma = np.array([0,1,1,1,0])\n",
    "    h = np.array([h1,1,1,h4,0])\n",
    "\n",
    "    y = np.dot(h,x)\n",
    "    beta = np.dot(gamma,x)\n",
    "\n",
    "    y = y.reshape(-1,1)\n",
    "    beta = beta.reshape(-1,1) #beta is our actual\n",
    "    r_model = LinearRegression()\n",
    "    r_model.fit(beta,y)\n",
    "    y_pred = r_model.predict(beta)\n",
    "    r2 = r2_score(beta,y)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(y)\n",
    "    plt.plot(beta)\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.scatter(y,beta)\n",
    "    plt.plot([-15,15],[-15,15],linestyle='dotted')\n",
    "    plt.xlim((-15,15))\n",
    "    plt.ylim((-15,15))\n",
    "    plt.text(16,10,'R2 ' + str(r2))\n",
    "    plt.text(16,5,'Slope ' + str(r_model.coef_))\n",
    "    plt.text(16,0,'Intercept ' + str(r_model.intercept_))\n",
    "\n",
    "    \n",
    "readout_widg = interactive(pva,noise1=(0,10,1),h1=(0,5,1),h4=(0,1,1))\n",
    "display(readout_widg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networked regions\n",
    "Finally we're going to look at a 'more realistic' set of brain regions, regions that communicate with each other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43cfde4a201845489cae5893f769d5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='noise1', max=10), IntSlider(value=0, description='h1', m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def pva_net(noise1=1,h1=0,h4=0):\n",
    "    n_nodes = 5\n",
    "    t = np.linspace(0,10,1000)\n",
    "    x = []\n",
    "    for ii in range(n_nodes):\n",
    "        x.append(np.sin(2 * np.pi * np.random.uniform(0,10) * t) + np.random.normal(0,noise1,size=t.shape))\n",
    "    x = np.array(x)\n",
    "    \n",
    "    network_G = nx.erdos_renyi_graph(n_nodes,0.8)\n",
    "    covar = nx.laplacian_matrix(network_G).todense()\n",
    "    corr_noise = np.random.multivariate_normal(mean=np.zeros((n_nodes,)), cov=covar,size=1000).T\n",
    "    x += corr_noise\n",
    "    \n",
    "    gamma = np.array([1,1,1,0,0])\n",
    "    h = np.array([h1,1,1,h4,0])\n",
    "\n",
    "    y = np.dot(h,x)\n",
    "    beta = np.dot(gamma,x)\n",
    "\n",
    "    y = y.reshape(-1,1)\n",
    "    beta = beta.reshape(-1,1)\n",
    "    r_model = LinearRegression()\n",
    "    r_model.fit(y,beta)\n",
    "    y_pred = r_model.predict(beta)\n",
    "    r2 = r2_score(beta,y) #REMEMBER R2_score asks for Actual, predicted\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.subplot(3,2,1)\n",
    "    plt.imshow(covar)\n",
    "    plt.subplot(3,2,2)\n",
    "    pos = nx.spring_layout(network_G)\n",
    "    idxs = np.where( gamma != 0)\n",
    "    nx.draw(network_G,pos=pos,node_color='black') #all nodes\n",
    "    dz_nodes = nx.draw_networkx_nodes(network_G,pos=pos,nodelist=list(idxs[0]),node_color='none',linewidths=8.0)# just the nodes related to disease\n",
    "    dz_nodes.set_edgecolor('blue')\n",
    "    nx.draw_networkx_nodes(network_G,pos=pos,nodelist=list(np.where(h != 0)[0]),node_color='green') #the nodes that are measured\n",
    "    \n",
    "    plt.subplot(3,1,2)\n",
    "    plt.plot(y)\n",
    "    plt.plot(beta)\n",
    "    plt.subplot(3,1,3)\n",
    "    plt.scatter(y,beta)\n",
    "    plt.plot([-15,15],[-15,15],linestyle='dotted')\n",
    "    plt.xlim((-15,15))\n",
    "    plt.ylim((-15,15))\n",
    "    plt.text(16,10,'R2 ' + str(r2))\n",
    "    plt.text(16,5,'Slope ' + str(r_model.coef_))\n",
    "    plt.text(16,0,'Intercept ' + str(r_model.intercept_))\n",
    "\n",
    "    \n",
    "readout_widg = interactive(pva_net,noise1=(0,10,1),h1=(0,5,1),h4=(0,1,1))\n",
    "display(readout_widg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonlinearities\n",
    "\n",
    "Here we'll set up a simple nonlinearity:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
